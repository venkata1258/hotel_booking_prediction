# -*- coding: utf-8 -*-
"""Hotel_Reservations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bneqrPMvxy7fpQvyWuEurMXhijKOGhPc
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('/content/Hotel Reservations.csv')
data.head()

data.shape

data.info()

data.isnull().sum()

data.drop("Booking_ID",axis=1,inplace = True)

data.describe()

numerical_cols = ['no_of_adults', 'no_of_children', 'no_of_weekend_nights', 'no_of_week_nights',
                  'required_car_parking_space','lead_time','arrival_year','arrival_month','arrival_date',
                  'repeated_guest','no_of_previous_cancellations','avg_price_per_room','no_of_special_requests']
plt.figure(figsize=(20, 15))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(3, 5, i)
    sns.histplot(data[col], kde=True)
    plt.title(col)
plt.tight_layout()
plt.show()

categorical_cols = ['type_of_meal_plan', 'room_type_reserved', 'market_segment_type']
for col in categorical_cols:
    plt.figure(figsize=(10,5))
    sns.countplot(data=data, x=col, hue='booking_status')
    plt.xticks(rotation=45)
    plt.legend(title='booking_status')
    plt.show()

numerical_cols = ['no_of_adults', 'no_of_children', 'no_of_weekend_nights', 'no_of_week_nights',
                  'required_car_parking_space','lead_time','arrival_year','arrival_month','arrival_date',
                  'repeated_guest','no_of_previous_cancellations','avg_price_per_room','no_of_special_requests']
plt.figure(figsize=(20, 15))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(3, 5, i)
    sns.boxplot(y=data[col])
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,8))
sns.heatmap(data[numerical_cols].corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# segerate input's and output's
X = data.drop('booking_status', axis=1)
y = data['booking_status']

num_col = X.select_dtypes(include=['int64','float64']).columns.tolist()
cat_col = X.select_dtypes(exclude=['int64','float64']).columns.tolist()

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTENC
from sklearn.pipeline import Pipeline
from sklearn import pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from keras.models import Sequential
from keras.layers import InputLayer,Dense,Dropout,BatchNormalization
from keras import regularizers
import tensorflow as tf
import keras.layers as layers

# x_trainval and x_test
X_trainval,X_test,y_trainval,y_test = train_test_split(X,y,test_size = 0.2,stratify=y,random_state=13)

print(X_trainval.shape)
print(X_test.shape)
print(y_trainval.shape)
print(y_test.shape)

# x_train and validation(x_trainval)
X_train,X_trainval,y_train,y_trainval = train_test_split(X_trainval,y_trainval,test_size=0.2,stratify=y_trainval,random_state=13)

print(X_train.shape)
print(X_trainval.shape)
print(y_train.shape)
print(y_trainval.shape)

# imbalancing
cat_indices = [X.columns.get_loc(col) for col in cat_col]
smote = SMOTENC(categorical_features=cat_indices, random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

print("before:",y_train.value_counts())
print("after:",y_train_res.value_counts())

y_train_res = y_train_res.replace({'Not_Canceled':0,'Canceled':1})
y_trainval = y_trainval.replace({'Not_Canceled':0,'Canceled':1})
y_test = y_test.replace({'Not_Canceled':0,'Canceled':1})

# pipeline
cat_pipeline = Pipeline([("simple_imputer",SimpleImputer(strategy="most_frequent")),
                         ("encoding", OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])
num_pipeline = Pipeline([("simple_imputer",SimpleImputer(strategy="median")),
                         ("scaling",StandardScaler())])
preprocessor = ColumnTransformer([("cat_transformation",cat_pipeline, cat_col),
                                  ("num_transformation",num_pipeline, num_col)])

# train
X_train_transformed = preprocessor.fit_transform(X_train_res)

# validation
X_trainval_transformed = preprocessor.transform(X_trainval)

# test
X_test_transformed = preprocessor.transform(X_test)

X_train_transformed = X_train_transformed.astype('float32')
X_trainval_transformed   = X_trainval_transformed.astype('float32')
X_test_transformed  = X_test_transformed.astype('float32')

# model structure
model = Sequential()
# input layer
model.add(InputLayer(input_shape=(X_train_transformed.shape[1],)))
# hidden layer 1
model.add(Dense(128,activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l1(0.003)))
model.add(BatchNormalization())
# hidden layer 2
model.add(Dense(64,activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l1(0.003)))
model.add(BatchNormalization())
# hidden layer 3
model.add(Dense(32,activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l1(0.003)))
model.add(BatchNormalization())
# output layer
model.add(Dense(1,activation='sigmoid',kernel_initializer="he_normal",kernel_regularizer=regularizers.l1(0.003)))

model.summary()

# model compile
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

history = model.fit(X_train_transformed, y_train_res,validation_data=(X_trainval_transformed, y_trainval),
                    epochs=50,batch_size=64)

plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.show()

# evalution
y_pred = (model.predict(X_test_transformed)>0.5).astype('int')

pd.Series(y_pred.flatten()).value_counts()

accuracy_score(y_test,y_pred)

#import joblib
#joblib.dump(preprocessor,'preprocessor.pkl')

!pip install keras-tuner

# hyperparameter tuning
import keras_tuner as kt

def build_model(hp):
    model = Sequential()
    # Input layer
    model.add(InputLayer(input_shape=(X_train_transformed.shape[1],)))
    # Hyperparameters
    units = hp.Int("units", min_value=32, max_value=256, step=32, default=128)
    activation_func = hp.Choice("activation", ["relu", "tanh", "sigmoid"], default="relu")
    dropout_rate = hp.Float("dropout_rate", min_value=0.0, max_value=0.5, step=0.05, default=0.25)
    l1 = hp.Float("l1", min_value=1e-5, max_value=1e-3, sampling="log", default=1e-4)
    initializer = hp.Choice("initializer",
                            ["he_normal", "he_uniform", "glorot_normal", "glorot_uniform"],
                            default="he_normal")
    num_layers = hp.Int("num_layers", 1, 5, default=3)
    for i in range(num_layers):
        model.add(Dense(units=units,activation=activation_func,kernel_initializer=initializer,
                        kernel_regularizer=regularizers.l1(l1)))
        model.add(BatchNormalization())
        if dropout_rate > 0.0:
            model.add(layers.Dropout(dropout_rate))
    # Output layer
    model.add(Dense(1,activation="sigmoid",kernel_initializer=initializer,kernel_regularizer=regularizers.l1(l1)))
    # Learning rate
    lr = hp.Float("lr", min_value=1e-5, max_value=1e-2, sampling="log", default=1e-3)
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    model.compile(optimizer=optimizer,loss="binary_crossentropy",metrics=["accuracy"])
    return model

import os
save_dir = "Hotel_Reservations"
os.makedirs(save_dir, exist_ok=True)
tuner = kt.Hyperband(build_model,objective='val_accuracy',max_epochs=20,directory=save_dir,project_name='Hyperparameter_Tuning',
    overwrite=True)
early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights = True)

# run search
tuner.search(
    X_train_transformed,y_train_res,
    epochs=20,
    batch_size=64,
    validation_data=(X_trainval_transformed,y_trainval),
    callbacks=[early_stop]
)

best_hyper = tuner.get_best_hyperparameters(num_trials=1)[0]
print("best hyperparameters:",best_hyper.values)
best_model = tuner.get_best_models(num_models=1)[0]
print(best_model)

best_model.save("hotel_cancellation_model.keras")
import joblib
joblib.dump(preprocessor, "preprocessor.pkl")

